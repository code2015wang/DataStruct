## 动态连接库

  **1 静态链接库的优点**  

   (1) 代码装载速度快，执行速度略比动态链接库快；  

   (2)  只需保证在开发者的计算机中有正确的.LIB文件，在以二进制形式发布程序时不需考虑在用户的计算机上.LIB文件是否存在及版本问题，可避免DLL地狱等问题。  

  **2 动态链接库的优点 **

   (1) 更加节省内存并减少页面交换； 

   (2)  DLL文件与EXE文件独立，只要输出接口不变（即名称、参数、返回值类型和调用约定不变），更换DLL文件不会对EXE文件造成任何影响，因而极大地提高了可维护性和可扩展性； 

   (3)  不同编程语言编写的程序只要按照函数调用约定就可以调用同一个DLL函数； 

   (4)适用于大规模的软件开发，使开发过程独立、耦合度小，便于不同开发者和开发组织之间进行开发和测试。 

  **3 不足之处**

   (1)  使用静态链接生成的可执行文件体积较大，包含相同的公共代码，造成浪费； 

   (2)  使用动态链接库的应用程序不是自完备的，它依赖的DLL模块也要存在，如果使用载入时动态链接，程序启动时发现DLL不存在，系统将终止程序并给出错误信息。而使用运行时动态链接，系统不会终止，但由于DLL中的导出函数不可用，程序会加载失败；速度比静态链接慢。当某个模块更新后，如果新模块与旧的模块不兼容，那么那些需要该模块才能运行的软件，统统撕掉。这在早期Windows中很常见。 

## n个数据选出最大的m个数的最小复杂度是0(n)

> 题目：输入n个整数，找出其中最小的k个数。例如输入4,5,1,6,2,7,3,8这8个数。则最小的4个数就是1,2,3,4.

这道题最简单的思路是把输入的n个整数排序，排序后位于最前面的k个数就是最小的k个数。这中思路的时间复杂度是O(nlogn).

解法一：O(n)的算法，只有我们可以修改输入数组的时候可用。

思路：如果基于数组的第k个数字来调整，使得比第k个数字小的所有数字都位于数组的左边，比第k个数字大的所有数字都位于数组的右边。这样调整之后，位于数组中的k个数字就是最小的k个数字（这k个数字不一定是排序的）

解法二：O(nlogk)的算法，特别适合处理海量数据

思路：我们可以创建一个大小为k的数据容器来存储最小的k个数字，接下来我们每次从输入的n个整数中读入一个数。如果容器中已有的数字少于k个，则直接把这次读入的整数放入容器之中。如果容器已有k个数字，也就是容器已满，此时我们不能在向容器中插入数字。我们要做3件事情：一是在k个整数中找到最大数;二是，有可能在这个容器中删除最大数;三是有可能要插入一个新的数字。如果用一个二叉树来实现这个容器，那麽我们就可以在O(logk)时间内实现这三步操作。因此对于n个输入数字而言，总的时间效率就是O(nlogk).我们可以选择不同的二叉树来实现这个数字容器，由于每次需要找到k个整数中的最大数字，我们很容易想到最大堆。

## top K问题

        在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。

        针对top 
K类问题，通常比较好的方案是分治+Trie树/hash+小顶堆（就是上面提到的最小堆），即先将数据集按照Hash方法分解成多个小数据集，然后使用Trie树活着Hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出现频率最高的前K个数，最后在所有top
 K中求出最终的top K。

eg：有1亿个浮点数，如果找出期中最大的10000个？


最容易想到的方法是将数据全部排序，然后在排序后的集合中进行查找，最快的排序算法的时间复杂度一般为O（nlogn），如快速排序。但是在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。其实即使内存能够满足要求（我机器内存都是8GB），该方法也并不高效，因为题目的目的是寻找出最大的10000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功。


第二种方法为局部淘汰法，该方法与排序方法类似，用一个容器保存前10000个数，然后将剩余的所有数字——与容器内的最小数字相比，如果所有后续的元素都比容器内的10000个数还小，那么容器内这个10000个数就是最大10000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O（n+m^2），其中m为容器的大小，即10000。


第三种方法是分治法，将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的100×*10000个数据里面找出最大的10000个。如果100万数据选择足够理想，那么可以过滤掉1亿数据里面99%的数据。100万个数据里面查找最大的10000个数据的方法如下：用快速排序的方法，将数据分为2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大堆个数N小于10000个，就在小的那堆里面快速排序一次，找第10000-n大的数字；递归以上过程，就可以找到第1w大的数。参考上面的找出第1w大数字，就可以类似的方法找到前10000大数字了。此种方法需要每次的内存空间为10^6*4=4MB，一共需要101次这样的比较。

        第四种方法是Hash法。如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数。


第五种方法采用最小堆。首先读入前10000个数来创建大小为10000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为10000），然后遍历后续的数字，并于堆顶（最小）数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后按照中序遍历的方式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）。

实际运行：

        实际上，最优的解决方案应该是最符合实际设计需求的方案，在时间应用中，可能有足够大的内存，那么直接将数据扔到内存中一次性处理即可，也可能机器有多个核，这样可以采用多线程处理整个数据集。

       下面针对不容的应用场景，分析了适合相应应用场景的解决方案。

（1）单机+单核+足够大内存


如果需要查找10亿个查询次（每个占8B）中出现频率最高的10个，考虑到每个查询词占8B，则10亿个查询次所需的内存大约是10^9 * 
8B=8GB内存。如果有这么大内存，直接在内存中对查询次进行排序，顺序遍历找出10个出现频率最大的即可。这种方法简单快速，使用。然后，也可以先用HashMap求出每个词出现的频率，然后求出频率最大的10个词。

（2）单机+多核+足够大内存

        这时可以直接在内存总使用Hash方法将数据划分成n个partition，每个partition交给一个线程处理，线程的处理逻辑同（1）类似，最后一个线程将结果归并。


该方法存在一个瓶颈会明显影响效率，即数据倾斜。每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。而针对此问题，解决的方法是，将数据划分成c×n个partition（c>1），每个线程处理完当前partition后主动取下一个partition继续处理，知道所有数据处理完毕，最后由一个线程进行归并。

（3）单机+单核+受限内存


这种情况下，需要将原数据文件切割成一个一个小文件，如次啊用hash(x)%M，将原文件中的数据切割成M小文件，如果小文件仍大于内存大小，继续采用Hash的方法对数据文件进行分割，知道每个小文件小于内存大小，这样每个文件可放到内存中处理。采用（1）的方法依次处理每个小文件。

（4）多机+受限内存

        这种情况，为了合理利用多台机器的资源，可将数据分发到多台机器上，每台机器采用（3）中的策略解决本地的数据。可采用hash+socket方法进行数据分发。


从实际应用的角度考虑，（1）（2）（3）（4）方案并不可行，因为在大规模数据处理环境下，作业效率并不是首要考虑的问题，算法的扩展性和容错性才是首要考虑的。算法应该具有良好的扩展性，以便数据量进一步加大（随着业务的发展，数据量加大是必然的）时，在不修改算法框架的前提下，可达到近似的线性比；算法应该具有容错性，即当前某个文件处理失败后，能自动将其交给另外一个线程继续处理，而不是从头开始处理。

        top K问题很适合采用MapReduce框架解决，用户只需编写一个Map函数和两个Reduce 
函数，然后提交到Hadoop（采用Mapchain和Reducechain）上即可解决该问题。具体而言，就是首先根据数据值或者把数据hash(MD5)后的值按照范围划分到不同的机器上，最好可以让数据划分后一次读入内存，这样不同的机器负责处理不同的数值范围，实际上就是Map。得到结果后，各个机器只需拿出各自出现次数最多的前N个数据，然后汇总，选出所有的数据中出现次数最多的前N个数据，这实际上就是Reduce过程。对于Map函数，采用Hash算法，将Hash值相同的数据交给同一个Reduce
 task；对于第一个Reduce函数，采用HashMap统计出每个词出现的频率，对于第二个Reduce 函数，统计所有Reduce 
task，输出数据中的top K即可。

        直接将数据均分到不同的机器上进行处理是无法得到正确的结果的。因为一个数据可能被均分到不同的机器上，而另一个则可能完全聚集到一个机器上，同时还可能存在具有相同数目的数据。

以下是一些经常被提及的该类问题。

（1）有10000000个记录，这些查询串的重复度比较高，如果除去重复后，不超过3000000个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。请统计最热门的10个查询串，要求使用的内存不能超过1GB。

（2）有10个文件，每个文件1GB，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。按照query的频度排序。

（3）有一个1GB大小的文件，里面的每一行是一个词，词的大小不超过16个字节，内存限制大小是1MB。返回频数最高的100个词。

（4）提取某日访问网站次数最多的那个IP。

（5）10亿个整数找出重复次数最多的100个整数。

（6）搜索的输入信息是一个字符串，统计300万条输入信息中最热门的前10条，每次输入的一个字符串为不超过255B，内存使用只有1GB。

（7）有1000万个身份证号以及他们对应的数据，身份证号可能重复，找出出现次数最多的身份证号。

重复问题

        在海量数据中查找出重复出现的元素或者去除重复出现的元素也是常考的问题。针对此类问题，一般可以通过位图法实现。例如，已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。

本题最好的解决方法是通过使用位图法来实现。8位整数可以表示的最大十进制数值为99999999。如果每个数字对应于位图中一个bit位，那么存储8位整数大约需要99MB。因为1B=8bit，所以99Mbit折合成内存为99/8=12.375MB的内存，即可以只用12.375MB的内存表示所有的8位数电话号码的内容。

## 哈夫曼树

哈夫曼树是一类带权路径长度最短的树。假设有n个权值{$ w_1$ ,$ w_2$ ,.....,$ w_n$ },试构造一课有n个叶子节点的二叉树，每个叶子节点带权为$ w_i $ ,则其中带权路径长度WPL最小的二叉树称为最优二叉树或哈夫曼树。

例如：由权值分别为1、12、13、4、8的叶子节点生成一颗哈夫曼树，它的带权路径长度为()

哈夫曼树如下： 

          38 

   *13          25 

            *12      13 

                     5      *8 

                *1     *4       

  其中带*为原始元素，总共4层（不算根节点） 带权路径长度 13×1 + 12×2 + 8*×3 + （1+4）×4 = 81 

> 工程师M发明了一种游戏：M将一个小球随机放入完全相同的三个盒子中的某一个，玩家选中装有球的盒子即获胜；开始时M会让玩家选择一个盒子（选择任何一个获胜概率均为1/3）;玩家做出选择后，M会打开没有被选择的两个盒子中的一个空盒，此时M会询问玩家是否更改选择（可以坚持第一次选择，也可以选择另一个没有打开的盒子）

> 这道题目容易弄错的地方就在于，把第二次选择当作整个游戏。如果跳过前面的排除，直接跳到第二次选择：你现有的和剩下的一个盒子中只有一个装了球。当然换或者不换获胜的概率都是   1/2，但是综合前面的情况来看，第二次选择  **获胜**  有两种情况：
>
>   \1. 不修改选择并**获胜**，表示第一次已经选对。概率为：1/3 * 1/2 = 1/6 
>
>   \2. 修改选择并      **获胜**，表示第一次选错。概率为：2/3 * 1/2 = 2/6
>
>          综上可知，第二次选择中修改选择后**获胜**的概率较大。
>
> ​      **       注意，**    **这里的 2/6 并不是整个游戏中改选的获胜概率！**第二次选择，胜负的概率各为 1/2，这里的 2/6 只是第二次选择中通过改选达到获胜的概率。
>
> ​      **       那整个游戏中改选获胜的概率是多少呢？**3 个盒子可能不容易看清，我们把问题改成：有 10    个盒子，选择完成之后移除 8 个空盒子。那么第一次选择的盒子有球的概率是 1/10，剩下 9 个盒子有球的概率是 9/10；移除 8    个空盒子相当于告诉你这 8 个盒子有球的概率为 0，但是 9个盒子有球的总概率为 9/10    是没有变的，这就表明剩下的那个盒子有球的概率是 9/10，如果改选这个盒子获胜的概率就是 9/10。同理，对于 3    个盒子，改选获胜的概率是 2/3，A 错

## **以下哪种方式，在读取磁盘上多个顺序数据块时的效率最高?**

  （1）程序直接访问方式跟循环检测IO方式，应该是一个意思吧，是最古老的方式。CPU和IO串行，每读一个字节（或字），CPU都需要不断检测状态寄存器的busy标志，当busy=1时，表示IO还没完成；当busy=0时，表示IO完成。此时读取一个字的过程才结束，接着读取下一个字。 

  （2）中断控制方式：循环检测先进些，IO设备和CPU可以并行工作，只有在开始IO和结束IO时，才需要CPU。但每次只能读取一个字。 

  （3）DMA方式：Direct Memory Access，直接存储器访问，比中断先进的地方是每次可以读取一个块，而不是一个字。 

  （4）通道方式：比DMA先进的地方是，每次可以处理多个块，而不只是一个块。 

## **进程间的通信方式的区别**

管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
 信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
套接字( socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。

## 大端与小端

#### 已知IBM的PowerPC是big-endian字节序列而Intel的X86是little-endian字节序，如果在地址啊存储的整形值时0x04030201，那么地址为a+3的字节内存储的值在PowerPC和Intel X86结构下的值分别是？

大端从大地址开始存储，小端相反，两者都是从数据低位开始存起；
 假设从上至下地址递增，则

  PowerPC（大）：                    Intel X86（小）：

  04                                            01                  低
  03                                            02                    |
  02                                            03                    | 
  01                                            04                   高
 a+3指向最大的地址，所以分别为1 4

大端模式是高低值存储数据的低字节，小端模式是高地址存储数据的高字节

## **TCP三次握手**

  Tcp/Ip有3次握手：第一次握手：客户端向服务器端发送SYN包（syn＝j），进入SYN_SEND状态，等待服务器确认。第二次握手：服务器收到SYN包，确认SYN，此时syn＝j+1，同时发送一个SYN包（syn＝k）即SYN＋ACK包，此时服务器进入SYN_RECV状态；第三次握手：客户端收到SYN＋ACK包，向服务器发送ACK确认包，此时客户端和服务器端均进入ESTABLISHED状态。 

  其中有一个半连接状态：服务器维护一个半连接队列，该队列卫每个客户端SYN包开设一个条目，标明服务器已经接到SYN包，并向客户端发出确认，这些条目表示的连接处于SYN_RECV状态，得到客户端的确认后进入ESTABLISHED状态。

## sizeof  

> `#pragma pack(2)`
>
> `class` `BU`
>
> `{`
>
> `    ``int` `number;`
>
> `    ``union` `UBffer`
>
> `    ``{`
>
> `        ``char` `buffer[13];`
>
> `        ``int` `number;`
>
> `    ``}ubuf;`
>
> `    ``void` `foo(){}`
>
> `    ``typedef` `char``*(*f)(``void``*);`
>
> `    ``enum``{hdd,ssd,blueray}disk;`
>
> `}bu;`

  union:当多个数据需要共享内存或者多个数据每次只取其一时，可以利用联合体(union)； 

  它有以下特点： 

      （1）它是一个结构；

      （2）它的所有成员相对于基地址的偏移量都为0； 

      （3）此结构空间要大到足够容纳最"宽"的成员； 

      （4）其对齐方式要适合其中所有的成员 

  综上： 

      而分配给union的实际大小不仅要满足是对齐大小的整数倍，同时要满足实际大小不能小于最大成员的大小。 

      本题目中

      注意第一行，#pragma pack(2) 

      首先考虑没有这句话时，我们在类、结构或者union补齐字节的时候，找它们的成员数据中找字节最大的那个数去衡量如何对齐，假设为z；

      但是有了这句话以后，对齐方式是取 pack(n)中n和z的最小值去对齐； 

      可见本题中对齐字节数为2；

      之后往下看 int number; 占4个字节 

      接下来考虑union大小

      union UBffer 

      { 

          char buffer[13]; // 13 

          int number; // 4 

      }ubuf; buffer 是13个字节，number 是4个字节，取最大的  为13，注意还要字节对齐，对齐字节数为2，所以Union大小为14，既满足buffer的对齐 也满足number的对齐。 

      void foo(){} 不占 

      typedef char*(*f)(void*); 不占 

      enum{hdd,ssd,blueray}disk; 4个字节 

 综上，总大小为14+4+0+0  +4=22  

## 线程共享   

同一个进程中的线程不共享的部分是()

​      **线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。**  

      进程拥有这许多共性的同时，还拥有自己的个性。有了这些个性，线程才能实现并发性。这些个性包括：

     1.线程ID
       每个线程都有自己的线程ID，这个ID在本进程中是唯一的。进程用此来标

     识线程。

      2.寄存器组的值
        由于线程间是并发运行的，每个线程有自己不同的运行线索，当从一个线

     程切换到另一个线程上  时，必须将原有的线程的寄存器集合的状态保存，以便

     将来该线程在被重新切换到时能得以恢复    

      3.线程的堆栈
        堆栈是保证线程独立运行所必须的。
        线程函数可以调用函数，而被调用函数中又是可以层层嵌套的，所以线程

     必须拥有自己的函数堆栈，  使得函数调用可以正常执行，不受其他线程的影

     响。

     4.错误返回码
        由于同一个进程中有很多个线程在同时运行，可能某个线程进行系统调用

     后设置了errno值，而在该  线程还没有处理这个错误，另外一个线程就在此时

     被调度器投入运行，这样错误值就有可能被修改。
        所以，不同的线程应该拥有自己的错误返回码变量。

     5.线程的信号屏蔽码
  由于每个线程所感兴趣的信号不同，所以线程的信号屏蔽码应该由线程自己管理。但所有的线程都共享同样的信号处理器。 

     6.线程的优先级
  由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级。    

        涉及多线程程序涉及的时候经常会出现一些令人难以思议的事情，用堆和栈分配一个变量可能在以后的执行中产生意想不到的结果，而这个结果的表现就是内存的非法被访问，导致内存的内容被更改。 
   理解这个现象的两个基本概念是：在一个进程的线程共享堆区，而进程中的线程各自维持自己堆栈。 

​     在 windows 等平台上，不同线程缺省使用同一个堆，所以用 C 的 malloc （或者 windows 的 
GlobalAlloc）分配内存的时候是使用了同步保护的。如果没有同步保护，在两个线程同时执行内存操作的时候会产生竞争条件，可能导致堆内内存管理混乱。比如两个线程分配了统一块内存地址，空闲链表指针错误等。 
​     Symbian 的线程一般使用独立的堆空间。这样每个线程可以直接在自己的堆里分配和释放，可以减少同步所引入的开销。当线程退出的时候，系统直接回收线程的堆空间，线程内没有释放的内存空间也不会造成进程内的内存泄漏。 
​     但是两个线程使用共用堆的时候，就必须用 critical section 或者 mutex进行同步保护。否则程序崩溃时早晚的事。如果你的线程需要在共用堆上无规则的分配和释放任何数量和类型的对象，可以定制一个自己的  allcator，在 allocator 内部使用同步保护。线程直接使用这个 allocato  分配内存就可以了。这相当于实现自己的  malloc，free。但是更建议你重新审查一下自己的系统，因为这种情况大多数是不必要的。经过良好的设计，线程的本地堆应该能够满足大多数对象的需求。如果有某一类对象需要在共享堆上创建和共享，这种需求是比较合理的，可以在这个类的  new 和 delete 上实现共享保护。 

## 分区分配

在动态分区分配方案中,系统回收主存,合并空闲空间时需修改空闲区表时

  在分区分配方案中，回收一个分区时有几种不同的邻接情况，在各种情况下应如何处理？ 答：有四种：上邻，下邻，上下相邻，上下不相邻。  

  （1）回收分区的上邻分区是空闲的，需要将两个相邻的空闲区合并成一个更大的空闲区，然后修改空闲区表。  

  （2）回收分区的下邻分区是空闲的，需要将两个相邻的空闲区合并成一个更大的空闲区，然后修改空闲区表。  

  （3）回收分区的上、下邻分区都是空闲的（空闲区个数为2），需要将三个空闲区合并成一个更大的空闲区（空闲区个数为1  ），然后修改空闲区表、 

  （4）回收分区的上、下邻分区都不是空闲的，则直接将空闲区记录在空闲区表中。 

>刚毕业的小王上班有两路公交车都可以从家到公司.如果只等A车,平均需要5分钟才等到;如果只等B车,平均需要7分钟才能等到.假定两辆车运行时间独立,那么小王平均需要等多长时间才能等到A车或B车?

> 在时间t内，A车t/5趟， B车t/7趟，所以在t内等到车共计t/5+t/7趟，等到一趟的时间则为t/(t/5+t/7)，等价35/12,